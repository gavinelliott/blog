---
title: 'From Eleanor to Thought-to-Action'
description: 'From a 2016 vision of “Eleanor” to a near future of thought-to-action—on disappearing interfaces, trust and building the skills for an anticipatory AI world.'
pubDate: '2025-08-08'
---

In 2016 I wrote [*A letter from the future*](/blog/a-letter-from-the-future/).  

It was a thought experiment about what life might look like when everything was connected. Not just our phones or our homes, but *us*. I imagined a world where a personal system called Eleanor knew me so well she could adjust my day before I even realised I needed it.  

She woke me up at the right moment. Had the shower running at the perfect temperature. Tracked my health without me asking. Gave me insights before meetings so I could adapt my approach. Handled my schedule, my meals, my commute.  

It was all about removing friction.  

At the time it felt bold. Now? It reads like an early draft.  

Because here we are in 2025 and I’m thinking about the next step. Not voice commands. Not screens. Not even AR glasses.  

I’m thinking about skipping the interface entirely.  

Last year I said typing would soon feel naive, replaced by voice. Now I’m not even convinced voice will hold its place for long. The future I’m looking at is thought-to-action. The gap between “I want to” and “it’s done” is shrinking fast.  

And here’s the thing. Back in 2016, Eleanor was still a layer I had to interact with. I had to ask her for things. Tell her what I needed. In the future that’s coming, the system will anticipate and act without a request.  

AI is getting better at context. At knowing what matters without you telling it. Hardware is catching up. Neural interfaces are starting to move from lab curiosity to something we’ll use in daily life.  

When that happens, the idea of pulling out a phone, typing, tapping or even speaking instructions will feel as quaint as dial-up internet.  

The conversation I keep having with myself is this, how do you design for that world? Because once the interface disappears, design stops being about screens and flows. It becomes about trust, transparency and intent. It becomes about making the invisible visible when it matters and letting it stay invisible when it doesn’t.  

## The pattern I keep seeing

Over the last year, I’ve been building small products — [Your Season Guide](https://yourseasonguide.com), [Best AI Things](https://bestaithings.com), [CleanReader](/blog/cleanreader/), [CV Anywhere](https://cvanywhere.com), [GPT Wrapper Apps](https://gptwrapperapps.com) and [Tonen](https://usetonen.com). None of them were built to be “the big one”. They were experiments.  

The goal was to learn by doing. Remove blockers. Get something real in front of people. And each time, the same thing happens:  

Something sparks an idea. I sketch it in my head. I open Cursor. I start prompting. I get a working version in the browser. I test it. I tweak it. I refine it. I launch it. And I learn.  

That pattern is exactly what’s preparing me for the thought-to-action world. Because in that world, the gap between the idea and the thing existing will be even smaller.  

The skill will not be in *whether* you can make something — it will be in knowing *what* to make and why it matters.  

## Looking forward

When I wrote about Eleanor in 2016, I was excited by the idea of a companion system that could help me live and work better. Now, the thought of having that level of anticipation without any visible interaction feels inevitable.  

We are closer than we think. And when we get there, we will look back at our keyboards, touchscreens and even voice assistants and wonder how we ever thought they were the peak of productivity.  

The real shift will not be in the tools we use, but in the way we think about what’s possible when the tools disappear entirely.
